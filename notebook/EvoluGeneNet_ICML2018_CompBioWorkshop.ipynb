{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvoluGeneNet_ICML2018_CompBioWorkshop.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh68rdepXlso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### CHH Yang 2018, ICML CompbioWorkshop 2018\n",
        "### contact: huckiyang @ github\n",
        "## https://github.com/huckiyang/EvoluGeneNet-Adjacency-Matrix-Visualizer\n",
        "#\n",
        "# If you find this useful in your work, please consider citing the following reference:\n",
        "# @article{yang2018learning,\n",
        "#   title={Learning Functions in Large Networks requires Modularity and produces Multi-Agent Dynamics},\n",
        "#   author={Yang, CH and Ooi, Rise and Hiscock, Tom and Eguiluz, Victor and Tegner, Jesper},\n",
        "#   journal={arXiv preprint arXiv:1807.03001},\n",
        "#   year={2018}\n",
        "# }\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "#########################ICML-IJCAI, Huck Yang, Rise Ooi, et al. 2018###########################\n",
        "## GeneNet Hyperparameters\n",
        "B       = 16       #batch size\n",
        "N       = 300       #timesteps\n",
        "S       = 3         #number of species\n",
        "dt      = 0.01      #time interval\n",
        "L1      = 0.003      #L1 regularization parameter\n",
        "\n",
        "## Genetic Algorithm Hyperparameters\n",
        "POP_SIZE = 12               # population size\n",
        "CLONES_NUM = 2               # Num of times of cloning, note: assert(POP_SIZE // CLONES_NO == 0)\n",
        "CROSS_RATE = 0.8              # mating probability (DNA crossover) (1 here because there are duplicates anyway)\n",
        "CROSS_POINT_RATE = 0.5     # DNA points crossover rate\n",
        "REVERSE_CROSS_RATE = 0.5     # Reverse crossover printing rate\n",
        "STEP_SIZE = 2               # mutation intensity\n",
        "N_GENERATIONS = 100          # generation number\n",
        "RAND_ITERATIONS = 100      # Initialization iterations\n",
        "GA_ITERATIONS = 100         # GA iterations\n",
        "PRUNE_ITERATIONS = 10     # Prune iterations\n",
        "IWV = 5                  # Initial value of the initial_weights_data elements\n",
        "#LOW_STEP_BOUND = 1 - STEP_SIZE\n",
        "#HIGH_STEP_BOUND = 1 + STEP_SIZE\n",
        "\n",
        "# Parameters (Derived from the hyperparameters, do not change anything)\n",
        "DNA_SIZE = S*S              # DNA length\n",
        "MUTATION_RATE = 0.5/DNA_SIZE        # mutation probability\n",
        "if(POP_SIZE%CLONES_NUM == 0):\n",
        "    SELECT_NUM = POP_SIZE//CLONES_NUM\n",
        "else:\n",
        "    raise AssertionError()\n",
        "\n",
        "####################################################################\n",
        "##Data \n",
        "input_      = tf.placeholder(tf.float32, shape=[N, B, S])\n",
        "output_     = tf.placeholder(tf.float32, shape=[B])\n",
        "initial_    = tf.placeholder(tf.float32, shape=[B, S])\n",
        "\n",
        "####################################################################\n",
        "##Variables to optimize\n",
        "W = tf.Variable(tf.random_normal([S,S], mean = 0, stddev = 0.1, dtype = tf.float32))\n",
        "A = tf.Variable(1.0, dtype = tf.float32)\n",
        "\n",
        "####################################################################\n",
        "##Nonlinearity chosen\n",
        "def phi(x):\n",
        "    return 1/(tf.exp(-x)+1)\n",
        "\n",
        "####################################################################\n",
        "##ODE function\n",
        "def simulate(input_, initial_, W):\n",
        "    output = tf.scan(lambda o,i: o + dt*(phi(tf.matmul(o,W))-o+i),\n",
        "                            elems = input_,\n",
        "                            initializer = initial_,\n",
        "                            swap_memory = True)\n",
        "    return output\n",
        "\n",
        "\n",
        "output = simulate(input_, initial_, W)\n",
        "\n",
        "####################################################################\n",
        "## Training function\n",
        "relevantOutput  = A*output[N-1,:,1]\n",
        "fullOutput \t\t= A*output[N-1,:,:]\n",
        "\n",
        "## Without regularization\n",
        "cost = tf.reduce_mean(tf.square(((relevantOutput - output_)))) \n",
        "train_step = tf.train.AdamOptimizer(learning_rate=0.2, beta1=0.98, beta2=0.999, epsilon=1e-08).minimize(cost)\n",
        "## With regularization\n",
        "costL1 = tf.reduce_mean(tf.square(((relevantOutput - output_)))) + L1*tf.reduce_mean(tf.abs(W)) \n",
        "train_stepL1 = tf.train.AdamOptimizer(learning_rate=0.2, beta1=0.98, beta2=0.999, epsilon=1e-08).minimize(costL1)\n",
        "\n",
        "####################################################################\n",
        "## Initial Weights Data\n",
        "initial_weights_data = []\n",
        "# # 0: BI type French Flag\n",
        "# initial_weights_data.append([[0, 0, 0],\n",
        "#                             [0, IWV, -IWV],\n",
        "#                             [-IWV, IWV, 0]])\n",
        "# # 1: OD type French Flag\n",
        "# initial_weights_data.append([[0, 0, -IWV],\n",
        "#                             [IWV, 0, 0],\n",
        "#                             [-IWV, IWV, 0]])\n",
        "# # 2: IFF type French Flag\n",
        "# initial_weights_data.append([[0, 0, 0],\n",
        "#                             [IWV, 0, 0],\n",
        "#                             [IWV, -IWV, IWV]])\n",
        "# # 3: MI type French Flag\n",
        "# initial_weights_data.append([[0, 0, 0],\n",
        "#                             [IWV, 0, -IWV],\n",
        "#                             [IWV, -IWV, 0]])\n",
        "# # 4: FO type French Flag\n",
        "# initial_weights_data.append([[IWV, 0, 0],\n",
        "#                             [-IWV, 0, IWV],\n",
        "#                             [-IWV, -IWV, IWV]])\n",
        "# # 5: Classical French Flag\n",
        "# initial_weights_data.append([[0, 0, 0],\n",
        "#                             [-IWV, IWV, 0],\n",
        "#                             [-IWV, -IWV, IWV]])\n",
        "\n",
        "## Direct Method\n",
        "# 0: BI type French Flag\n",
        "initial_weights_data.append([[-4.62, -7.50, -7.77],\n",
        "                            [-9.59, 16.07, -15.26],\n",
        "                            [-18.12, 5.88, -5.99]])\n",
        "# 1: OD type French Flag\n",
        "initial_weights_data.append([[-43.88, -6.45, -16.36],\n",
        "                            [46.57, 14.83, -11.99],\n",
        "                            [-35.90, 1.80, -14.28]])\n",
        "# 2: IFF type French Flag\n",
        "initial_weights_data.append([[0.17, 4.85, -1.03],\n",
        "                            [0.11, 0.13, -2.23],\n",
        "                            [-0.06, -7.48, 4.28]])\n",
        "# 3: MI type French Flag\n",
        "initial_weights_data.append([[-1.28, -2.27, -5.70],\n",
        "                            [-0.15, 8.92, 0.29],\n",
        "                            [0.02, -5.45, 8.46]])\n",
        "# 4: FO type French Flag\n",
        "initial_weights_data.append([[-1.30, -2.19, -5.44],\n",
        "                            [-0.59, 8.55, 0.52],\n",
        "                            [-0.13, -5.41, 7.79]])\n",
        "# 5: Classical French Flag\n",
        "initial_weights_data.append([[-2.82079792, 0.7832284, -5.42571878],\n",
        "                            [-0.22299732, -0.26842004, 0.46841779],\n",
        "                            [-3.14926434, -5.17239904, 8.41496181]])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CszRhvmyXzcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "####################################################################\n",
        "## Training data - here for a \"stripe\"\n",
        "def newBatch(plot=False):\n",
        "    initialVal      = 0.1*np.ones([B,S])\n",
        "    if(plot):\n",
        "        inputNoNoise = np.linspace(0,2,B)\n",
        "    else:\n",
        "        inputNoNoise    = np.random.uniform(0,2,B)\n",
        "    inputVal        = inputNoNoise.reshape(B,1) * np.random.normal(loc=1.0, scale = 0.0001, size=[N,B,S])\n",
        "    inputVal[:,:,1:S] = 0.0\n",
        "    outputNoNoise   = np.zeros_like(inputNoNoise)\n",
        "    #outputNoNoise[inputNoNoise > 1.0] = 1.0 # Original PlotAll\n",
        "    outputNoNoise[np.logical_and(inputNoNoise > 0.5,inputNoNoise < 1.5 )] = 1.0\n",
        "    return [inputVal, outputNoNoise, initialVal]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSlTLlLOX4nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################################################\n",
        "## Training model function\n",
        "# Original GeneNet trainModel with tweaks\n",
        "def trainModel(iterations,regularize=False,prune=False,pruneLimit=1,printing=False):\n",
        "    mask = np.abs(sess.run(W)) > pruneLimit\n",
        "    for i in range(iterations):\n",
        "        [inputVal, outputVal, initialVal] = newBatch()\n",
        "        if(regularize):\n",
        "            sess.run(train_stepL1, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "        else:\n",
        "            sess.run(train_step, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "        if(printing):\n",
        "            ww = sess.run(cost, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "            weights = sess.run(W)\n",
        "            print([ww, i/iterations],end=\"\\r\")\n",
        "        if(prune):\n",
        "            applyMask = W.assign(W*mask)\n",
        "            sess.run(applyMask)\n",
        "            \n",
        "    ww = sess.run(cost, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "    outputW = sess.run(W)\n",
        "    outputA = sess.run(A)\n",
        "    return ww, outputW, outputA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra9YCzy8X7MA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Original GeneNet randomized trainModel outputting weights and cost\n",
        "def trainRandomModel(iterations,initial=-1,regularize=False,prune=False,pruneLimit=1,printing=False):\n",
        "    # There is no failing mechanism if initial is less than -1 or more than 5\n",
        "    if(initial <= -1):\n",
        "        randomize_W = W.assign(tf.random_normal([S,S], mean = 0, stddev = 0.1, dtype = tf.float32))\n",
        "        sess.run(randomize_W)\n",
        "    elif(initial>=0 and initial<=5):\n",
        "        set_W = W.assign(initial_weights_data[initial])\n",
        "        sess.run(set_W)\n",
        "    else:\n",
        "        raise AssertionError()\n",
        "        \n",
        "    randomize_A = A.assign(1.0)\n",
        "    sess.run(randomize_A)\n",
        "    \n",
        "    mask = np.abs(sess.run(W)) > pruneLimit\n",
        "    for i in range(iterations):\n",
        "        [inputVal, outputVal, initialVal] = newBatch()\n",
        "        if(regularize):\n",
        "            sess.run(train_stepL1, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "        else:\n",
        "            sess.run(train_step, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "        if(printing):\n",
        "            ww = sess.run(cost, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "            outputW = sess.run(W)\n",
        "            print([ww, i/iterations],end=\"\\r\")\n",
        "        if(prune):\n",
        "            applyMask = W.assign(W*mask)\n",
        "            sess.run(applyMask)\n",
        "    \n",
        "    ww = sess.run(cost, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "    outputW = sess.run(W)\n",
        "    outputA = sess.run(A)\n",
        "    return ww, outputW, outputA\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfH2I76GX-I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Incomplete function. # TODO: Uses previously trained weights and cost to retrain them. \n",
        "def trainEvolvingModel(iterations, evolved_w, evolved_a, regularize=False,prune=False,pruneLimit=1,printing=False):\n",
        "    set_W = W.assign(evolved_w)\n",
        "    set_A = A.assign(evolved_a)\n",
        "    sess.run(set_W)\n",
        "    sess.run(set_A)\n",
        "    mask = np.abs(sess.run(W)) > pruneLimit\n",
        "    for i in range(iterations):\n",
        "        [inputVal, outputVal, initialVal] = newBatch()\n",
        "        if(regularize):\n",
        "            sess.run(train_stepL1, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "        else:\n",
        "            sess.run(train_step, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "        if(printing):\n",
        "            ww = sess.run(cost, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "            outputW = sess.run(W)\n",
        "            print([ww, i/iterations],end=\"\\r\")\n",
        "        if(prune):\n",
        "            applyMask = W.assign(W*mask)\n",
        "            sess.run(applyMask)\n",
        "    \n",
        "    ww = sess.run(cost, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "    outputW = sess.run(W)\n",
        "    outputA = sess.run(A)\n",
        "    return ww, outputW, outputA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfktOpwdX-xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "####################################################################\n",
        "## Simulate model\n",
        "def simulateModel():\n",
        "    [inputVal, outputVal, initialVal] = newBatch(plot=True)\n",
        "    finalOutput = sess.run(fullOutput, feed_dict = {input_: inputVal, initial_: initialVal, output_: outputVal})\n",
        "    print(sess.run(W))\n",
        "    print(sess.run(A))\n",
        "    for j in np.arange(0,S):\n",
        "        plt.plot(finalOutput[:,j])\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h-j-ns-YBIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################################################\n",
        "## GA Functions\n",
        "# TODO: Upgrade the selection method to use rank method with diversity selector built in\n",
        "def selection(w_storage, a_storage):    # selecting most fit half of population (no diversity built in)\n",
        "    # Assuming children number is even\n",
        "    # Assuming w_storage are sorted\n",
        "    w_ret = []\n",
        "    a_ret = []\n",
        "    for i in range(SELECT_NUM):\n",
        "        for _ in range(CLONES_NUM):\n",
        "            w_ret.append(w_storage[i])\n",
        "            a_ret.append(a_storage[i])\n",
        "    return w_ret, a_ret\n",
        "\n",
        "def crossover(population):     # mating process (genes crossover)\n",
        "    for i in range(POP_SIZE):\n",
        "        if np.random.rand() < CROSS_RATE:\n",
        "        #if True: # Since there are duplicates, there's 20% chance it won't cross over anyway.\n",
        "            crossover_target = np.random.randint(POP_SIZE)\n",
        "            for j in range(DNA_SIZE):\n",
        "                if np.random.rand() < CROSS_POINT_RATE:\n",
        "                    if np.random.rand() < REVERSE_CROSS_RATE:\n",
        "                        # printing from crossover_target WITH reverse printing (exchange)\n",
        "                        reverse_tmp = population[i][j]\n",
        "                        population[i][j] = population[crossover_target][j]\n",
        "                        population[crossover_target][j] = reverse_tmp\n",
        "                    else:\n",
        "                        # no reverse printing\n",
        "                        population[i][j] = population[crossover_target][j]\n",
        "                    \n",
        "            \n",
        "    return population\n",
        "\n",
        "#TODO: Should we mutate A?\n",
        "def mutate(population):\n",
        "    for i in range(POP_SIZE):\n",
        "        for j in range(DNA_SIZE):\n",
        "            if np.random.rand() < MUTATION_RATE:\n",
        "                # If STEP_SIZE is 1, it will only scales from 0~1\n",
        "                # Default STEP_SIZE is 2, but should be increased according to type of problem\n",
        "                # (-1)**np.random.randint(2) gives either -1 or 1\n",
        "                population[i][j] *= STEP_SIZE*np.random.rand() * (-1)**np.random.randint(2)\n",
        "                # New mutation way:\n",
        "                #population[i][j] *= STEP_SIZE * -1\n",
        "\n",
        "    return population"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQQLmTeWYD9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Roll & Unrolling\n",
        "def unroll(_list):\n",
        "    ret = []\n",
        "    for i in range(S):\n",
        "        for j in range(S):\n",
        "            ret.append(_list[i][j])\n",
        "            \n",
        "    return ret\n",
        "\n",
        "def roll(_list):\n",
        "    ret = []\n",
        "    _list.append(0) # delete if possible\n",
        "    for i in range(S):\n",
        "        ret.append(_list[i*S:i*S+3])\n",
        "\n",
        "    return ret\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0CYlfBeYGRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#Triple mergesort sorting by alist\n",
        "#TODO: convert cost_storage, w_storage, and a_storage into one single dictionary instead of three lists\n",
        "def triple_mergesort(alist, blist, clist):\n",
        "    #print(\"Splitting \",alist)\n",
        "    if len(alist)>1:\n",
        "        mid = len(alist)//2\n",
        "        lefthalf_a = alist[:mid]\n",
        "        lefthalf_b = blist[:mid]\n",
        "        lefthalf_c = clist[:mid]\n",
        "        righthalf_a = alist[mid:]\n",
        "        righthalf_b = blist[mid:]\n",
        "        righthalf_c = clist[mid:]\n",
        "         \n",
        "\n",
        "        triple_mergesort(lefthalf_a, lefthalf_b, lefthalf_b)\n",
        "        triple_mergesort(righthalf_a, righthalf_b, righthalf_c)\n",
        "\n",
        "        i=0\n",
        "        j=0\n",
        "        k=0\n",
        "        while i < len(lefthalf_a) and j < len(righthalf_a):\n",
        "            if lefthalf_a[i] < righthalf_a[j]:\n",
        "                alist[k]=lefthalf_a[i]\n",
        "                blist[k]=lefthalf_b[i]\n",
        "                clist[k]=lefthalf_c[i]\n",
        "                i=i+1\n",
        "            else:\n",
        "                alist[k]=righthalf_a[j]\n",
        "                blist[k]=righthalf_b[j]\n",
        "                clist[k]=righthalf_c[j]\n",
        "                j=j+1\n",
        "            k=k+1\n",
        "\n",
        "        while i < len(lefthalf_a):\n",
        "            alist[k]=lefthalf_a[i]\n",
        "            blist[k]=lefthalf_b[i]\n",
        "            clist[k]=lefthalf_c[i]\n",
        "            i=i+1\n",
        "            k=k+1\n",
        "\n",
        "        while j < len(righthalf_a):\n",
        "            alist[k]=righthalf_a[j]\n",
        "            blist[k]=righthalf_b[j]\n",
        "            clist[k]=righthalf_c[j]\n",
        "            j=j+1\n",
        "            k=k+1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b3lghJQYIaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "####################################################################\n",
        "## Determine type\n",
        "# type_table = np.zeros(3**9)\n",
        "# def update_type_table(trained_weights, type_table):\n",
        "#     flat_w = []\n",
        "#     for i in range(S):\n",
        "#         for j in range(S):\n",
        "#             flat_w.append(trained_weights[i][j])\n",
        "#     for i in range(POP_SIZE):\n",
        "#         index = 0\n",
        "#         for j in range(DNA_SIZE):\n",
        "#             if (flat_w[j] <= -1):\n",
        "#                 index += 0\n",
        "#             elif (flat_w[j] >= 1):\n",
        "#                 index += 3**j\n",
        "#             else:\n",
        "#                 index += 2*(3**j)\n",
        "#         # note: index's binaries are in reverse\n",
        "#         type_table[index] += 1\n",
        "        \n",
        "#     return type_table;\n",
        "\n",
        "## Determine not classical type straight away and stores the child number and generation\n",
        "type_dict_table = {}\n",
        "def determine_type(tw, type_dict_table):\n",
        "    # tw means trained_weights\n",
        "    return type_dict_table\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2rhtEdVYMlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "####################################################################\n",
        "## GA-Layered Train model\n",
        "sess = tf.InteractiveSession()\n",
        "tf.global_variables_initializer().run()\n",
        "\n",
        "##Global Storage\n",
        "# Note that the weights are not converted to anything else from real form.\n",
        "cost_storage = []     # Cost lookup table\n",
        "w_storage = [];       # Stores children weights\n",
        "a_storage = [];       # Stores A\n",
        "\n",
        "\n",
        "# Initialize random children and stores them to weights_storage\n",
        "# Assume POP_SIZE is 12\n",
        "for p in range(POP_SIZE):\n",
        "    t1 = time.time()\n",
        "    print(\"\\nRandomly initialized Child #\",p)\n",
        "    child_cost, child_w, child_a = trainRandomModel(iterations=RAND_ITERATIONS, initial=p//2)\n",
        "    #simulateModel()\n",
        "    #print(\"After regularize...\")\n",
        "    #child_cost, child_w, child_a = trainModel(iterations=PRUNE_ITERATIONS, regularize=True)\n",
        "    #simulateModel()\n",
        "    #print(\"After pruning...\")\n",
        "    #child_cost, child_w, child_a = trainModel(iterations=PRUNE_ITERATIONS, prune=True)\n",
        "    simulateModel()\n",
        "    print(\"Cost:\", child_cost)\n",
        "    cost_storage.append(child_cost)\n",
        "    w_storage.append(child_w)\n",
        "    a_storage.append(child_a)\n",
        "    t2 = time.time()\n",
        "    print(\"Time: \", t2-t1)\n",
        "\n",
        "#print(cost_storage)\n",
        "#print(w_storage)\n",
        "#print(a_storage)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}